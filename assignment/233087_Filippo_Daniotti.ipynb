{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb67ba8d",
   "metadata": {},
   "source": [
    "# NLU: Mid-Term Assignment 2022\n",
    "### Description\n",
    "In this notebook, we ask you to complete four main tasks to show what you have learnt during the NLU labs. Therefore, to complete the assignment please refer to the concepts, libraries and other materials shown and used during the labs. The last task is not mandatory, it is a *BONUS* to get an extra mark for the laude. \n",
    "\n",
    "### Instructions\n",
    "- **Dataset**: in this notebook, you are asked to work with the dataset *Conll 2003* provided by us in the *data* folder. Please, load the files from the *data* folder and **do not** change names or paths of the inner files. \n",
    "- **Output**: for each part of your task, print your results and leave it in the notebook. Please, **do not** send a jupyter notebook without the printed outputs.\n",
    "- **Other**: follow carefully all the further instructions and suggestions given in the question descriptions.\n",
    "\n",
    "### Deadline\n",
    "The deadline is due in two weeks from the project presentation. Please, refer to *piazza* channel for the exact date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3c05fb",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb069d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "from nltk.lm import Vocabulary\n",
    "from nltk.corpus import ConllCorpusReader\n",
    "\n",
    "CORPUS_ROOT = 'data'\n",
    "CORPUS_FILEIDS = ['train.txt', 'test.txt', 'valid.txt']\n",
    "CORPUS_COLUMNTYPES = ['words', 'ne', 'pos', 'chunk', 'tree']\n",
    "\n",
    "corpus = ConllCorpusReader(CORPUS_ROOT, CORPUS_FILEIDS, CORPUS_COLUMNTYPES)\n",
    "corpus_train = ConllCorpusReader(CORPUS_ROOT, CORPUS_FILEIDS[0], CORPUS_COLUMNTYPES)\n",
    "corpus_test = ConllCorpusReader(CORPUS_ROOT, CORPUS_FILEIDS[1], CORPUS_COLUMNTYPES)\n",
    "corpus_val = ConllCorpusReader(CORPUS_ROOT, CORPUS_FILEIDS[2], CORPUS_COLUMNTYPES)\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('./src/'))\n",
    "from conll import evaluate\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Utilities\n",
    "def nbest(d, n=1):\n",
    "    \"\"\"\n",
    "    get n max values from a dict\n",
    "    :param d: input dict (values are numbers, keys are stings)\n",
    "    :param n: number of values to get (int)\n",
    "    :return: dict of top n key-value pairs\n",
    "    \"\"\"\n",
    "    return dict(sorted(d.items(), key=lambda item: item[1], reverse=True)[:n])\n",
    "\n",
    "def get_flat_sents(corpus):\n",
    "    sents = list()\n",
    "    for sent in corpus:\n",
    "        flat_sent = \"\"\n",
    "        for w in sent:\n",
    "            flat_sent += f\"{w} \"\n",
    "        sents.append(flat_sent.strip())\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d123d",
   "metadata": {},
   "source": [
    "## Task 1: Analysis of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead0d1f",
   "metadata": {},
   "source": [
    "### Q 1.1\n",
    "- Create the Vocabulary and Frequency Dictionary of the:\n",
    "    1. Whole dataset\n",
    "    2. Train set\n",
    "    3. Test set\n",
    "    \n",
    "**Attention**: print the first 20 words of the Dictionaty of each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca1124f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of whole dataset: 26869\n",
      "Length of train set: 21009\n",
      "Length of test set: 8548\n",
      "\n",
      "First 20 words of whole dataset:\n",
      "{'the': 12310, ',': 10876, '.': 10874, 'of': 5502, 'in': 5405, 'to': 5129, 'a': 4731, '(': 4226, ')': 4225, 'and': 4223, '\"': 3239, 'on': 3115, 'said': 2694, \"'s\": 2339, 'for': 2109, '-': 1866, '1': 1845, 'at': 1679, 'was': 1593, '2': 1342}\n",
      "\n",
      "First 20 words of train set:\n",
      "{'the': 8390, '.': 7374, ',': 7290, 'of': 3815, 'in': 3621, 'to': 3424, 'a': 3199, 'and': 2872, '(': 2861, ')': 2861, '\"': 2178, 'on': 2092, 'said': 1849, \"'s\": 1566, 'for': 1465, '1': 1421, '-': 1243, 'at': 1146, 'was': 1095, '2': 973}\n",
      "\n",
      "First 20 words of test set:\n",
      "{'the': 1765, ',': 1637, '.': 1626, 'to': 805, 'of': 789, 'in': 761, '(': 686, ')': 684, 'a': 658, 'and': 598, 'on': 467, '\"': 421, 'said': 399, \"'s\": 347, '-': 287, 'for': 286, 'at': 251, 'was': 224, '4': 201, 'with': 185}\n"
     ]
    }
   ],
   "source": [
    "def q11():\n",
    "    # Create vocabulary\n",
    "    vocab = set([w.lower() for w in corpus.words()])\n",
    "    vocab_train = set([w.lower() for w in corpus_train.words()])\n",
    "    vocab_test = set([w.lower() for w in corpus_test.words()])\n",
    "\n",
    "    # Create frequency distribution\n",
    "    fd = FreqDist([w.lower() for w in corpus.words()])\n",
    "    fd_train = FreqDist([w.lower() for w in corpus_train.words()])\n",
    "    fd_test = FreqDist([w.lower() for w in corpus_test.words()])\n",
    "\n",
    "    # Print vocabulary length\n",
    "    print(\"Length of whole dataset: %d\" % len(vocab))\n",
    "    print(\"Length of train set: %d\" % len(vocab_train))\n",
    "    print(\"Length of test set: %d\" % len(vocab_test))\n",
    "\n",
    "    # Print the first 20 words for each dict\n",
    "    print(\"\\nFirst 20 words of whole dataset:\")\n",
    "    print(nbest(fd, 20))\n",
    "    print(\"\\nFirst 20 words of train set:\")\n",
    "    print(nbest(fd_train, 20))\n",
    "    print(\"\\nFirst 20 words of test set:\")\n",
    "    print(nbest(fd_test, 20))\n",
    "\n",
    "q11()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0dc02f",
   "metadata": {},
   "source": [
    "### Q 1.2\n",
    "- Obtain the list of:\n",
    "    1. Out-Of-Vocabulary (OOV) tokens\n",
    "    2. Overlapping tokens between train and test sets  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b660bcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q1.2.1]\n",
      ">\tOOV tokens:\n",
      ">\t (test) Found 3268 OOV\n",
      ">\t (valid) Found 2856 OOV\n",
      ">\t (test + valid) Found 0 OOV\n",
      "\n",
      "[Q1.2.1]\n",
      ">\tOverlapping tokens:\n",
      ">\t (test) Found 5280 overlapping tokens\n",
      ">\t (valid) Found 6146 overlapping tokens\n",
      ">\t (test + val) Found 8066 overlapping tokens\n"
     ]
    }
   ],
   "source": [
    "def q12(cutoff=1):\n",
    "\n",
    "\n",
    "    test_lower = [w.lower() for w in corpus_test.words()]\n",
    "    val_lower = [w.lower() for w in corpus_val.words()]\n",
    "    # Get vocabs\n",
    "    vocab_train = Vocabulary([w.lower() for w in corpus_train.words()], unk_cutoff=cutoff)\n",
    "    vocab_test = Vocabulary(test_lower, unk_cutoff=cutoff)\n",
    "    vocab_valid = Vocabulary(val_lower, unk_cutoff=cutoff)\n",
    "    vocab_tv = Vocabulary([*test_lower, *val_lower], unk_cutoff=cutoff)\n",
    "\n",
    "    # Get list of tokens\n",
    "    tokens_train = set(vocab_train.counts.keys())\n",
    "    tokens_test = set(vocab_test.counts.keys())\n",
    "    tokens_val = set(vocab_valid.counts.keys())\n",
    "    tokens_tv = set(vocab_tv.counts.keys())\n",
    "\n",
    "    # Get OOV \n",
    "    oov_test = tokens_test.difference(tokens_train)\n",
    "    oov_valid = tokens_val.difference(tokens_train)\n",
    "    oov_tv = tokens_val.difference(tokens_tv)\n",
    "    print(\"[Q1.2.1]\\n>\\tOOV tokens:\")\n",
    "    print(\">\\t (test) Found {} OOV\".format(len(oov_test)))\n",
    "    print(\">\\t (valid) Found {} OOV\".format(len(oov_valid)))\n",
    "    print(\">\\t (test + valid) Found {} OOV\".format(len(oov_tv)))\n",
    "\n",
    "    print()\n",
    "\n",
    "    # Get overlapping tokens w/ test set\n",
    "    intersection_test = tokens_train.intersection(tokens_test)\n",
    "    intersection_val = tokens_train.intersection(tokens_val)\n",
    "    intersection_tv = tokens_train.intersection(tokens_tv)\n",
    "    print(\"[Q1.2.1]\\n>\\tOverlapping tokens:\")\n",
    "    print(\">\\t (test) Found {} overlapping tokens\".format(len(intersection_test)))\n",
    "    print(\">\\t (valid) Found {} overlapping tokens\".format(len(intersection_val)))\n",
    "    print(\">\\t (test + val) Found {} overlapping tokens\".format(len(intersection_tv)))\n",
    "    \n",
    "\n",
    "q12()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab1ac1c",
   "metadata": {},
   "source": [
    "### Q 1.3\n",
    "- Perform a complete data analysis of the whole dataset (train + test sets) to obtain:\n",
    "    1. Average sentence length computed in number of tokens\n",
    "    2. The 50 most-common tokens\n",
    "    3. Number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "36e5c39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q1.3.1]\n",
      ">\tAverage sentence length in tokens: 13.6160\n",
      "\n",
      "[Q1.3.2]\n",
      ">\t50 most common tokens:\n",
      ">\t[1] the: 12310\n",
      ">\t[2] ,: 10876\n",
      ">\t[3] .: 10874\n",
      ">\t[4] of: 5502\n",
      ">\t[5] in: 5405\n",
      ">\t[6] to: 5129\n",
      ">\t[7] a: 4731\n",
      ">\t[8] (: 4226\n",
      ">\t[9] ): 4225\n",
      ">\t[10] and: 4223\n",
      ">\t[11] \": 3239\n",
      ">\t[12] on: 3115\n",
      ">\t[13] said: 2694\n",
      ">\t[14] 's: 2339\n",
      ">\t[15] for: 2109\n",
      ">\t[16] -: 1866\n",
      ">\t[17] 1: 1845\n",
      ">\t[18] at: 1679\n",
      ">\t[19] was: 1593\n",
      ">\t[20] 2: 1342\n",
      ">\t[21] with: 1267\n",
      ">\t[22] 3: 1264\n",
      ">\t[23] 0: 1232\n",
      ">\t[24] that: 1212\n",
      ">\t[25] he: 1166\n",
      ">\t[26] from: 1146\n",
      ">\t[27] by: 1113\n",
      ">\t[28] it: 1082\n",
      ">\t[29] :: 1057\n",
      ">\t[30] is: 984\n",
      ">\t[31] 4: 973\n",
      ">\t[32] as: 920\n",
      ">\t[33] his: 867\n",
      ">\t[34] had: 841\n",
      ">\t[35] were: 804\n",
      ">\t[36] an: 796\n",
      ">\t[37] but: 786\n",
      ">\t[38] not: 786\n",
      ">\t[39] after: 780\n",
      ">\t[40] has: 768\n",
      ">\t[41] be: 754\n",
      ">\t[42] have: 738\n",
      ">\t[43] new: 656\n",
      ">\t[44] first: 645\n",
      ">\t[45] who: 643\n",
      ">\t[46] 5: 636\n",
      ">\t[47] will: 591\n",
      ">\t[48] 6: 584\n",
      ">\t[49] two: 579\n",
      ">\t[50] they: 567\n",
      "\n",
      "[Q1.3.3]\n",
      ">\tNumber of sentences: 22137\n"
     ]
    }
   ],
   "source": [
    "def q13():\n",
    "\n",
    "    # Get average sentence length\n",
    "    print(\"[Q1.3.1]\\n>\\tAverage sentence length in tokens: {:.4f}\\n\".format(len(corpus.words())/len(corpus.sents())))\n",
    "\n",
    "    # Get 50 most common tokens\n",
    "    vocab = Vocabulary([w.lower() for w in corpus.words()])\n",
    "    most_common_tokens = nbest(vocab.counts, 50)\n",
    "    print(\"[Q1.3.2]\\n>\\t50 most common tokens:\")\n",
    "    # print(\">\\t\", most_common_tokens)\n",
    "    count = 1\n",
    "    for key in most_common_tokens:\n",
    "        print(\">\\t[{}] {}: {}\".format(count, key, most_common_tokens[key]))\n",
    "        count += 1\n",
    "\n",
    "    # Get number of sentences\n",
    "    print(\"\\n[Q1.3.3]\\n>\\tNumber of sentences: %d\" % len(corpus.sents()))\n",
    "\n",
    "q13()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726af097",
   "metadata": {},
   "source": [
    "### Q 1.4\n",
    "- Create the dictionary of Named Entities and their Frequencies for the:\n",
    "    1. Whole dataset\n",
    "    2. Train set\n",
    "    3. Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5659670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q1.4.1]\n",
      ">\tFrequency dist of Named Entities for the whole dataset\n",
      ">\t {'U.S.': 460, 'Germany': 237, 'Australia': 204, 'France': 199, 'England': 176, 'Russia': 167, 'Britain': 165, 'Italy': 160, 'China': 149, 'LONDON': 147, 'Spain': 145, 'NEW YORK': 143, 'Japan': 133, 'Russian': 120, 'German': 114, 'Reuters': 114, 'Israel': 108, 'Sweden': 108, 'Pakistan': 103, 'Iraq': 98}\n",
      "[Q1.4.2]\n",
      ">\tFrequency dist of Named Entities for the training set\n",
      ">\t {'U.S.': 303, 'Germany': 141, 'Britain': 133, 'Australia': 130, 'England': 123, 'France': 122, 'Spain': 110, 'Italy': 98, 'NEW YORK': 95, 'LONDON': 93, 'Russian': 92, 'China': 91, 'Russia': 88, 'Japan': 87, 'Pakistan': 85, 'Sweden': 81, 'German': 80, 'British': 73, 'Reuters': 73, 'Belgium': 71}\n",
      "[Q1.4.3]\n",
      ">\tFrequency dist of Named Entities for the test set\n",
      ">\t {'Germany': 49, 'U.S.': 45, 'Australia': 45, 'Japan': 41, 'Italy': 41, 'France': 40, 'World Cup': 34, 'Russia': 34, 'Indonesia': 33, 'China': 32, 'LONDON': 31, 'Austria': 29, 'Barcelona': 24, 'Canada': 23, 'NEW YORK': 22, 'England': 21, 'Singapore': 21, 'Poland': 20, 'Reuters': 19, 'WTO': 19}\n"
     ]
    }
   ],
   "source": [
    "def q14():\n",
    "    WORD, _, NE = range(3)\n",
    "\n",
    "    def merge_iob_tags(doc):\n",
    "        idx = 0\n",
    "        merged_ne = list()\n",
    "        for idx in range(len(doc)):\n",
    "            if doc[idx][NE].split('-')[0] == \"B\":\n",
    "                temp = str(doc[idx][WORD])\n",
    "                idx += 1\n",
    "                while idx < len(doc) and doc[idx][NE].split('-')[0] == \"I\":\n",
    "                    temp += \" %s\" % str(doc[idx][WORD])\n",
    "                    idx += 1\n",
    "                merged_ne.append(temp)\n",
    "        return merged_ne\n",
    "\n",
    "    # Whole dataset\n",
    "    iob_all = [(w[WORD], _, w[NE]) for w in corpus.iob_words() if w[NE] != 'O']\n",
    "    ne_all = merge_iob_tags(iob_all)\n",
    "    fd_all = FreqDist(ne_all)\n",
    "    print(\"[Q1.4.1]\\n>\\tFrequency dist of Named Entities for the whole dataset\\n>\\t\", nbest(fd_all, 20))\n",
    "\n",
    "    # Train set\n",
    "    iob_train = [(w[WORD], _, w[NE]) for w in corpus_train.iob_words() if w[NE] != 'O']\n",
    "    ne_train = merge_iob_tags(iob_train)\n",
    "    fd_train = FreqDist(ne_train)\n",
    "    print(\"[Q1.4.2]\\n>\\tFrequency dist of Named Entities for the training set\\n>\\t\", nbest(fd_train, 20))\n",
    "\n",
    "    # Test set\n",
    "    iob_test = [(w[WORD], _, w[NE]) for w in corpus_test.iob_words() if w[NE] != 'O']\n",
    "    ne_test = merge_iob_tags(iob_test)\n",
    "    fd_test = FreqDist(ne_test)\n",
    "    print(\"[Q1.4.3]\\n>\\tFrequency dist of Named Entities for the test set\\n>\\t\", nbest(fd_test, 20))\n",
    "\n",
    "q14()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a08f37",
   "metadata": {},
   "source": [
    "## Task 2: Working with Dependecy Tree\n",
    "*Suggestions: use Spacy pipeline to retreive the Dependecy Tree*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1ba597",
   "metadata": {},
   "source": [
    "### Q 2.1\n",
    "- Given each sentence in the dataset, write the required functions to provide:\n",
    "    1. Subject, obects (direct and indirect)\n",
    "    2. Noun chunks\n",
    "    3. The head noun in each noun chunk\n",
    "    \n",
    "**Attention**: *print only the results of these functions by using the sentence \"I saw the man with a telescope\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f6292d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "[Q2.1.1]\n",
      ">\tProviding subjects and objects:\n",
      ">\t nsubj: []\n",
      ">\t dobj: []\n",
      ">\t pobj: []\n",
      "\n",
      "[Q2.1.2]\n",
      ">\tProviding noun chunks:\n",
      "\n",
      "[Q2.1.3]\n",
      ">\tProviding head noun for each noun chunk:\n",
      ">\t'CHUNK' -> HEAD\n",
      ">\n",
      "\n",
      "EU rejects German call to boycott British lamb . \n",
      "\n",
      "[Q2.1.1]\n",
      ">\tProviding subjects and objects:\n",
      ">\t nsubj: ['EU']\n",
      ">\t dobj: ['call', 'lamb']\n",
      ">\t pobj: []\n",
      "\n",
      "[Q2.1.2]\n",
      ">\tProviding noun chunks:\n",
      ">\t EU\n",
      ">\t German call\n",
      ">\t British lamb\n",
      "\n",
      "[Q2.1.3]\n",
      ">\tProviding head noun for each noun chunk:\n",
      ">\t'CHUNK' -> HEAD\n",
      ">\n",
      ">\t'EU' -> EU\n",
      ">\t'German call' -> call\n",
      ">\t'British lamb' -> lamb\n",
      "\n",
      "Peter Blackburn \n",
      "\n",
      "[Q2.1.1]\n",
      ">\tProviding subjects and objects:\n",
      ">\t nsubj: []\n",
      ">\t dobj: []\n",
      ">\t pobj: []\n",
      "\n",
      "[Q2.1.2]\n",
      ">\tProviding noun chunks:\n",
      ">\t Peter Blackburn\n",
      "\n",
      "[Q2.1.3]\n",
      ">\tProviding head noun for each noun chunk:\n",
      ">\t'CHUNK' -> HEAD\n",
      ">\n",
      ">\t'Peter Blackburn' -> Blackburn\n",
      "\n",
      "BRUSSELS 1996-08-22 \n",
      "\n",
      "[Q2.1.1]\n",
      ">\tProviding subjects and objects:\n",
      ">\t nsubj: []\n",
      ">\t dobj: []\n",
      ">\t pobj: []\n",
      "\n",
      "[Q2.1.2]\n",
      ">\tProviding noun chunks:\n",
      ">\t BRUSSELS\n",
      "\n",
      "[Q2.1.3]\n",
      ">\tProviding head noun for each noun chunk:\n",
      ">\t'CHUNK' -> HEAD\n",
      ">\n",
      ">\t'BRUSSELS' -> BRUSSELS\n",
      "\n",
      "The European Commission said on Thursday it disagreed with German advice to consumers to shun British lamb until scientists determine whether mad cow disease can be transmitted to sheep . \n",
      "\n",
      "[Q2.1.1]\n",
      ">\tProviding subjects and objects:\n",
      ">\t nsubj: ['Commission', 'it', 'scientists']\n",
      ">\t dobj: ['lamb']\n",
      ">\t pobj: ['Thursday', 'advice', 'consumers', 'sheep']\n",
      "\n",
      "[Q2.1.2]\n",
      ">\tProviding noun chunks:\n",
      ">\t The European Commission\n",
      ">\t Thursday\n",
      ">\t it\n",
      ">\t German advice\n",
      ">\t consumers\n",
      ">\t British lamb\n",
      ">\t scientists\n",
      ">\t mad cow disease\n",
      ">\t sheep\n",
      "\n",
      "[Q2.1.3]\n",
      ">\tProviding head noun for each noun chunk:\n",
      ">\t'CHUNK' -> HEAD\n",
      ">\n",
      ">\t'The European Commission' -> Commission\n",
      ">\t'Thursday' -> Thursday\n",
      ">\t'it' -> it\n",
      ">\t'German advice' -> advice\n",
      ">\t'consumers' -> consumers\n",
      ">\t'British lamb' -> lamb\n",
      ">\t'scientists' -> scientists\n",
      ">\t'mad cow disease' -> disease\n",
      ">\t'sheep' -> sheep\n",
      "\n",
      "Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer . \n",
      "\n",
      "[Q2.1.1]\n",
      ">\tProviding subjects and objects:\n",
      ">\t nsubj: ['representative', 'Zwingmann', 'consumers', 'advice']\n",
      ">\t dobj: ['sheepmeat']\n",
      ">\t pobj: ['committee', 'Wednesday', 'countries', 'Britain']\n",
      "\n",
      "[Q2.1.2]\n",
      ">\tProviding noun chunks:\n",
      ">\t Germany 's representative\n",
      ">\t the European Union 's veterinary committee\n",
      ">\t Werner Zwingmann\n",
      ">\t Wednesday\n",
      ">\t consumers\n",
      ">\t sheepmeat\n",
      ">\t countries\n",
      ">\t Britain\n",
      ">\t the scientific advice\n",
      "\n",
      "[Q2.1.3]\n",
      ">\tProviding head noun for each noun chunk:\n",
      ">\t'CHUNK' -> HEAD\n",
      ">\n",
      ">\t'Germany 's representative' -> representative\n",
      ">\t'the European Union 's veterinary committee' -> committee\n",
      ">\t'Werner Zwingmann' -> Zwingmann\n",
      ">\t'Wednesday' -> Wednesday\n",
      ">\t'consumers' -> consumers\n",
      ">\t'sheepmeat' -> sheepmeat\n",
      ">\t'countries' -> countries\n",
      ">\t'Britain' -> Britain\n",
      ">\t'the scientific advice' -> advice\n",
      "\n",
      "\" We do n't support any such recommendation because we do n't see any grounds for it , \" the Commission 's chief spokesman Nikolaus van der Pas told a news briefing . \n",
      "\n",
      "[Q2.1.1]\n",
      ">\tProviding subjects and objects:\n",
      ">\t nsubj: ['We', 'we', 'Pas']\n",
      ">\t dobj: ['recommendation', 'grounds', 'briefing']\n",
      ">\t pobj: ['it']\n",
      "\n",
      "[Q2.1.2]\n",
      ">\tProviding noun chunks:\n",
      ">\t We\n",
      ">\t any such recommendation\n",
      ">\t we\n",
      ">\t any grounds\n",
      ">\t it\n",
      ">\t the Commission 's chief spokesman Nikolaus van der Pas\n",
      ">\t a news briefing\n",
      "\n",
      "[Q2.1.3]\n",
      ">\tProviding head noun for each noun chunk:\n",
      ">\t'CHUNK' -> HEAD\n",
      ">\n",
      ">\t'We' -> We\n",
      ">\t'any such recommendation' -> recommendation\n",
      ">\t'we' -> we\n",
      ">\t'any grounds' -> grounds\n",
      ">\t'it' -> it\n",
      ">\t'the Commission 's chief spokesman Nikolaus van der Pas' -> Pas\n",
      ">\t'a news briefing' -> briefing\n",
      "\n",
      "He said further scientific study was required and if it was found that action was needed it should be taken by the European Union . \n",
      "\n",
      "[Q2.1.1]\n",
      ">\tProviding subjects and objects:\n",
      ">\t nsubj: ['He']\n",
      ">\t dobj: []\n",
      ">\t pobj: ['Union']\n",
      "\n",
      "[Q2.1.2]\n",
      ">\tProviding noun chunks:\n",
      ">\t He\n",
      ">\t further scientific study\n",
      ">\t it\n",
      ">\t action\n",
      ">\t it\n",
      ">\t the European Union\n",
      "\n",
      "[Q2.1.3]\n",
      ">\tProviding head noun for each noun chunk:\n",
      ">\t'CHUNK' -> HEAD\n",
      ">\n",
      ">\t'He' -> He\n",
      ">\t'further scientific study' -> study\n",
      ">\t'it' -> it\n",
      ">\t'action' -> action\n",
      ">\t'it' -> it\n",
      ">\t'the European Union' -> Union\n",
      "\n",
      "He said a proposal last month by EU Farm Commissioner Franz Fischler to ban sheep brains , spleens and spinal cords from the human and animal food chains was a highly specific and precautionary move to protect human health . \n",
      "\n",
      "[Q2.1.1]\n",
      ">\tProviding subjects and objects:\n",
      ">\t nsubj: ['He']\n",
      ">\t dobj: ['proposal', 'brains', 'health']\n",
      ">\t pobj: ['Fischler', 'chains']\n",
      "\n",
      "[Q2.1.2]\n",
      ">\tProviding noun chunks:\n",
      ">\t He\n",
      ">\t a proposal\n",
      ">\t EU Farm Commissioner Franz Fischler\n",
      ">\t sheep brains\n",
      ">\t spleens\n",
      ">\t spinal cords\n",
      ">\t the human and animal food chains\n",
      ">\t a highly specific and precautionary move\n",
      ">\t human health\n",
      "\n",
      "[Q2.1.3]\n",
      ">\tProviding head noun for each noun chunk:\n",
      ">\t'CHUNK' -> HEAD\n",
      ">\n",
      ">\t'He' -> He\n",
      ">\t'a proposal' -> proposal\n",
      ">\t'EU Farm Commissioner Franz Fischler' -> Fischler\n",
      ">\t'sheep brains' -> brains\n",
      ">\t'spleens' -> spleens\n",
      ">\t'spinal cords' -> cords\n",
      ">\t'the human and animal food chains' -> chains\n",
      ">\t'a highly specific and precautionary move' -> move\n",
      ">\t'human health' -> health\n",
      "\n",
      "Fischler proposed EU-wide measures after reports from Britain and France that under laboratory conditions sheep could contract Bovine Spongiform Encephalopathy ( BSE ) -- mad cow disease . \n",
      "\n",
      "[Q2.1.1]\n",
      ">\tProviding subjects and objects:\n",
      ">\t nsubj: ['Fischler', 'sheep']\n",
      ">\t dobj: ['measures', 'Spongiform', 'Encephalopathy']\n",
      ">\t pobj: ['reports', 'Britain']\n",
      "\n",
      "[Q2.1.2]\n",
      ">\tProviding noun chunks:\n",
      ">\t Fischler\n",
      ">\t EU-wide measures\n",
      ">\t reports\n",
      ">\t Britain\n",
      ">\t France\n",
      ">\t laboratory conditions sheep\n",
      ">\t Bovine Spongiform\n",
      ">\t Encephalopathy\n",
      ">\t ( BSE\n",
      ">\t mad cow disease\n",
      "\n",
      "[Q2.1.3]\n",
      ">\tProviding head noun for each noun chunk:\n",
      ">\t'CHUNK' -> HEAD\n",
      ">\n",
      ">\t'Fischler' -> Fischler\n",
      ">\t'EU-wide measures' -> measures\n",
      ">\t'reports' -> reports\n",
      ">\t'Britain' -> Britain\n",
      ">\t'France' -> France\n",
      ">\t'laboratory conditions sheep' -> sheep\n",
      ">\t'Bovine Spongiform' -> Spongiform\n",
      ">\t'Encephalopathy' -> Encephalopathy\n",
      ">\t'( BSE' -> BSE\n",
      ">\t'mad cow disease' -> disease\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def q21(corpus):\n",
    "\n",
    "    def get_subj_obj_dict(doc):\n",
    "        deps_dict = dict()\n",
    "        deps = ['nsubj', 'dobj', 'pobj']\n",
    "        for dep in deps:\n",
    "            deps_dict[dep] = list()\n",
    "        for token in doc:\n",
    "            if token.dep_ in deps:\n",
    "                deps_dict[token.dep_].append(token.text)\n",
    "        return deps_dict\n",
    "                    \n",
    "    def get_noun_chunks(doc):\n",
    "        return doc.noun_chunks\n",
    "\n",
    "    def get_head_of_chunk(doc):\n",
    "        return [(c.root.text, c.text) for c in doc.noun_chunks]\n",
    "\n",
    "\n",
    "    def q211(doc):\n",
    "        print(\"[Q2.1.1]\\n>\\tProviding subjects and objects:\")\n",
    "        deps_dict = get_subj_obj_dict(doc)\n",
    "        for key in deps_dict:\n",
    "            print(\">\\t {}: {}\".format(key, deps_dict[key]))\n",
    "        print()\n",
    "\n",
    "\n",
    "    def q212(doc):\n",
    "        print(\"[Q2.1.2]\\n>\\tProviding noun chunks:\")\n",
    "        noun_chunks = get_noun_chunks(doc)\n",
    "        for chunk in noun_chunks:\n",
    "            print(\">\\t\", chunk)\n",
    "        print()\n",
    "\n",
    "    def q213(doc):\n",
    "        print(\"[Q2.1.3]\\n>\\tProviding head noun for each noun chunk:\")\n",
    "        print(\">\\t'CHUNK' -> HEAD\\n>\")\n",
    "        heads = get_head_of_chunk(doc)\n",
    "        for head, chunk in heads:\n",
    "            print(\">\\t'{}' -> {}\".format(chunk, head))\n",
    "        print()\n",
    "\n",
    "\n",
    "    sents = get_flat_sents(corpus)\n",
    "    for sent in sents[:10]:\n",
    "        doc = nlp(sent)\n",
    "        print (sent, \"\\n\")\n",
    "        q211(doc)\n",
    "        q212(doc)\n",
    "        q213(doc)\n",
    "\n",
    "    # doc = nlp(sents[14])\n",
    "    # print (sents[14], \"\\n\")\n",
    "    # q211(doc)\n",
    "    # q212(doc)\n",
    "    # q213(doc)\n",
    "\n",
    "\n",
    "# q21([\"I saw the man with a telescope\".split(\" \")])\n",
    "q21(corpus.sents())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84838829",
   "metadata": {},
   "source": [
    "### Q 2.2\n",
    "- Given a dependecy tree of a sentence and a segment of that sentence write the required functions that ouput the dependency subtree of that segment.\n",
    "\n",
    "**Attention**: *print only the results of these functions by using the sentence \"I saw the man with a telescope\" (the segment could be any e.g. \"saw the man\", \"a telescope\", etc.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8d524e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The EU 's scientific veterinary and multidisciplinary committees are due to re-examine the issue early next month and make recommendations to the senior veterinary officials\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c02ef6050a014b8cba9b8fe5298ffb7c-0\" class=\"displacy\" width=\"4600\" height=\"574.5\" direction=\"ltr\" style=\"max-width: none; height: 574.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">EU</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">'s</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">scientific</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">veterinary</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">multidisciplinary</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">committees</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">are</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">due</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">re-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">examine</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">issue</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2675\">early</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2675\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2850\">next</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2850\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3025\">month</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3025\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3375\">make</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3375\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3550\">recommendations</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3550\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3725\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3725\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3900\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3900\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4075\">senior</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4075\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4250\">veterinary</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4250\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"484.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"4425\">officials</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"4425\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-0\" stroke-width=\"2px\" d=\"M70,439.5 C70,352.0 205.0,352.0 205.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,441.5 L62,429.5 78,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-1\" stroke-width=\"2px\" d=\"M245,439.5 C245,264.5 735.0,264.5 735.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,441.5 L237,429.5 253,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-2\" stroke-width=\"2px\" d=\"M245,439.5 C245,352.0 380.0,352.0 380.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M380.0,441.5 L388.0,429.5 372.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-3\" stroke-width=\"2px\" d=\"M595,439.5 C595,352.0 730.0,352.0 730.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,441.5 L587,429.5 603,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-4\" stroke-width=\"2px\" d=\"M770,439.5 C770,177.0 1265.0,177.0 1265.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,441.5 L762,429.5 778,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-5\" stroke-width=\"2px\" d=\"M770,439.5 C770,352.0 905.0,352.0 905.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M905.0,441.5 L913.0,429.5 897.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-6\" stroke-width=\"2px\" d=\"M770,439.5 C770,264.5 1085.0,264.5 1085.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1085.0,441.5 L1093.0,429.5 1077.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-7\" stroke-width=\"2px\" d=\"M1295,439.5 C1295,352.0 1430.0,352.0 1430.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,441.5 L1287,429.5 1303,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-8\" stroke-width=\"2px\" d=\"M1470,439.5 C1470,352.0 1605.0,352.0 1605.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1605.0,441.5 L1613.0,429.5 1597.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-9\" stroke-width=\"2px\" d=\"M1820,439.5 C1820,352.0 1955.0,352.0 1955.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,441.5 L1812,429.5 1828,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-10\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,264.5 1960.0,264.5 1960.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1960.0,441.5 L1968.0,429.5 1952.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-11\" stroke-width=\"2px\" d=\"M1645,439.5 C1645,177.0 2140.0,177.0 2140.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2140.0,441.5 L2148.0,429.5 2132.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-12\" stroke-width=\"2px\" d=\"M2345,439.5 C2345,352.0 2480.0,352.0 2480.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2345,441.5 L2337,429.5 2353,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-13\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,264.5 2485.0,264.5 2485.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2485.0,441.5 L2493.0,429.5 2477.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-14\" stroke-width=\"2px\" d=\"M2695,439.5 C2695,264.5 3010.0,264.5 3010.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2695,441.5 L2687,429.5 2703,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-15\" stroke-width=\"2px\" d=\"M2870,439.5 C2870,352.0 3005.0,352.0 3005.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2870,441.5 L2862,429.5 2878,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-16\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,177.0 3015.0,177.0 3015.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3015.0,441.5 L3023.0,429.5 3007.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-17\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,89.5 3195.0,89.5 3195.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3195.0,441.5 L3203.0,429.5 3187.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-18\" stroke-width=\"2px\" d=\"M2170,439.5 C2170,2.0 3375.0,2.0 3375.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3375.0,441.5 L3383.0,429.5 3367.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-19\" stroke-width=\"2px\" d=\"M3395,439.5 C3395,352.0 3530.0,352.0 3530.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3530.0,441.5 L3538.0,429.5 3522.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-20\" stroke-width=\"2px\" d=\"M3570,439.5 C3570,352.0 3705.0,352.0 3705.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3705.0,441.5 L3713.0,429.5 3697.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-21\" stroke-width=\"2px\" d=\"M3920,439.5 C3920,177.0 4415.0,177.0 4415.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M3920,441.5 L3912,429.5 3928,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-22\" stroke-width=\"2px\" d=\"M4095,439.5 C4095,264.5 4410.0,264.5 4410.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4095,441.5 L4087,429.5 4103,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-23\" stroke-width=\"2px\" d=\"M4270,439.5 C4270,352.0 4405.0,352.0 4405.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4270,441.5 L4262,429.5 4278,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-24\" stroke-width=\"2px\" d=\"M3745,439.5 C3745,89.5 4420.0,89.5 4420.0,439.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c02ef6050a014b8cba9b8fe5298ffb7c-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M4420.0,441.5 L4428.0,429.5 4412.0,429.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: The EU 's scientific veterinary and multidisciplinary committees\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c3c9f483cab2495aa5efb7778b131ba1-0\" class=\"displacy\" width=\"1450\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">EU</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">'s</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">scientific</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">veterinary</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">multidisciplinary</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">committees</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c3c9f483cab2495aa5efb7778b131ba1-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c3c9f483cab2495aa5efb7778b131ba1-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c3c9f483cab2495aa5efb7778b131ba1-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c3c9f483cab2495aa5efb7778b131ba1-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c3c9f483cab2495aa5efb7778b131ba1-0-2\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c3c9f483cab2495aa5efb7778b131ba1-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M390.0,266.5 L398.0,254.5 382.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c3c9f483cab2495aa5efb7778b131ba1-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c3c9f483cab2495aa5efb7778b131ba1-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c3c9f483cab2495aa5efb7778b131ba1-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,2.0 1275.0,2.0 1275.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c3c9f483cab2495aa5efb7778b131ba1-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c3c9f483cab2495aa5efb7778b131ba1-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c3c9f483cab2495aa5efb7778b131ba1-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c3c9f483cab2495aa5efb7778b131ba1-0-6\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c3c9f483cab2495aa5efb7778b131ba1-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: the issue\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"eedb218e90c8459a8e692167d0b38a80-0\" class=\"displacy\" width=\"400\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">issue</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-eedb218e90c8459a8e692167d0b38a80-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-eedb218e90c8459a8e692167d0b38a80-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: recommendations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a5db7092aed14d02819ce9e49b8c4aee-0\" class=\"displacy\" width=\"225\" height=\"137.0\" direction=\"ltr\" style=\"max-width: none; height: 137.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">recommendations</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: the senior veterinary officials\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ef703a18d43f4e53aae2bfe1bdcd5eb3-0\" class=\"displacy\" width=\"750\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">senior</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">veterinary</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">officials</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ef703a18d43f4e53aae2bfe1bdcd5eb3-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ef703a18d43f4e53aae2bfe1bdcd5eb3-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ef703a18d43f4e53aae2bfe1bdcd5eb3-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ef703a18d43f4e53aae2bfe1bdcd5eb3-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ef703a18d43f4e53aae2bfe1bdcd5eb3-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ef703a18d43f4e53aae2bfe1bdcd5eb3-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def q22(corpus):\n",
    "\n",
    "    def get_root(doc):\n",
    "        for token in doc:\n",
    "            if token.dep_ == 'ROOT':\n",
    "                return token.text \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    def get_subtree(chunk_text, doc):\n",
    "        subtree = None\n",
    "        chunk_doc = nlp(chunk_text)\n",
    "        chunk_root = get_root(chunk_doc)\n",
    "        for token in doc:\n",
    "            if token.text == chunk_root:\n",
    "                leftmost = list(token.subtree)[0].i\n",
    "                rightmost = list(token.subtree)[-1].i\n",
    "                subtree = doc[leftmost:rightmost+1]\n",
    "        return subtree\n",
    "\n",
    "\n",
    "    sents = get_flat_sents(corpus)\n",
    "    sents = [sents[14]]\n",
    "    for sent in sents:\n",
    "        print(sent)\n",
    "        doc = nlp(sent)\n",
    "        spacy.displacy.render(doc, style=\"dep\")\n",
    "        for chunk in doc.noun_chunks:\n",
    "            # subtree = get_subtree(chunk.text, doc)\n",
    "            # print(\"Chunk: {}\\n>\\tSubtree: {}\".format(chunk, chunk))\n",
    "            print(\"Chunk: {}\".format(chunk))\n",
    "            spacy.displacy.render(chunk, style=\"dep\")\n",
    "    \n",
    "# q22([\n",
    "#     \"I saw the man with the telescope\".split(\" \"),\n",
    "#     \"I saw the man with a telescope\".split(\" \")\n",
    "# ])\n",
    "q22(corpus.sents())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292e99ac",
   "metadata": {},
   "source": [
    "### Q 2.3\n",
    "- Given a token in a sentence, write the required functions that output the dependency path from the root of the dependency tree to that given token.\n",
    "\n",
    "**Attention**: *print only the results of these functions by using the sentence \"I saw the man with a telescope\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3b0b1106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I saw the man with a telescope on the hill \n",
      "TOKEN ---> ['path', 'to', 'root']\n",
      "\n",
      "I\n",
      "\t---> ['I', 'saw']\n",
      "saw\n",
      "\t---> ['saw']\n",
      "the\n",
      "\t---> ['the', 'man', 'saw']\n",
      "man\n",
      "\t---> ['man', 'saw']\n",
      "with\n",
      "\t---> ['with', 'saw']\n",
      "a\n",
      "\t---> ['a', 'telescope', 'with', 'saw']\n",
      "telescope\n",
      "\t---> ['telescope', 'with', 'saw']\n",
      "on\n",
      "\t---> ['on', 'telescope', 'with', 'saw']\n",
      "the\n",
      "\t---> ['the', 'hill', 'on', 'telescope', 'with', 'saw']\n",
      "hill\n",
      "\t---> ['hill', 'on', 'telescope', 'with', 'saw']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ceba3225710a4a03ab7d726bb5de4ad5-0\" class=\"displacy\" width=\"1800\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">saw</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">man</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">telescope</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">hill</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-1\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-2\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,266.5 L578.0,254.5 562.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-3\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,266.5 L758.0,254.5 742.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-6\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1265.0,266.5 L1273.0,254.5 1257.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-8\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,89.5 1620.0,89.5 1620.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ceba3225710a4a03ab7d726bb5de4ad5-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1620.0,266.5 L1628.0,254.5 1612.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def q23(corpus):\n",
    "        # print()\n",
    "    def compute_dependency_path(token):\n",
    "        path = list()\n",
    "        path.append(token.text)\n",
    "        while token.dep_ != 'ROOT':\n",
    "            token = token.head\n",
    "            path.append(token.text)\n",
    "        return path\n",
    "\n",
    "    sents = get_flat_sents(corpus)\n",
    "    for sent in sents:\n",
    "        print(sent)\n",
    "        doc = nlp(sent)\n",
    "        print(\"TOKEN ---> ['path', 'to', 'root']\\n\")\n",
    "        for token in doc:\n",
    "            print(\"{}\\n\\t---> {}\".format(token.text, compute_dependency_path(token)))\n",
    "\n",
    "    spacy.displacy.render(doc, style=\"dep\")\n",
    "\n",
    "q23([\"I saw the man with a telescope on the hill\".split(\" \")])\n",
    "# q23(corpus.sents())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3358779",
   "metadata": {},
   "source": [
    "## Task 3: Named Entity Recognition\n",
    "*Suggestion: use scikit-learn metric functions. See classification_report*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c820ad69",
   "metadata": {},
   "source": [
    "### Q 3.1\n",
    "- Benchmark Spacy Named Entity Recognition model on the test set by:\n",
    "    1. Providing the list of categories in the dataset (person, organization, etc.)\n",
    "    2. Computing the overall accuracy on NER\n",
    "    3. Computing the performance of the Named Entity Recognition model for each category:\n",
    "        - Compute the perfomance at the token level (eg. B-Person, I-Person, B-Organization, I-Organization, O, etc.)\n",
    "        - Compute the performance at the entity level (eg. Person, Organization, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2e92688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting processed dataset\n",
    "sents_train = get_flat_sents(corpus_train.sents())\n",
    "docs_train = [nlp(sent) for sent in sents_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2ab4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_all = get_flat_sents(corpus.sents())\n",
    "docs_all = [nlp(sent) for sent in sents_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c18d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_test = get_flat_sents(corpus_test.sents())\n",
    "docs_test = [nlp(sent) for sent in sents_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab185dc4",
   "metadata": {},
   "source": [
    "#### Q 3.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca542d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(docs):\n",
    "    categories = set()\n",
    "    for doc in docs:\n",
    "        # doc = nlp(sent)\n",
    "        for token in doc:\n",
    "            categories.add(token.ent_type_)\n",
    "        if '' in categories:\n",
    "            categories.discard('')\n",
    "    return list(categories)\n",
    "\n",
    "def q311(docs):\n",
    "    print(\"[Q3.1.1]\\n>\\tProviding list of categories in the dataset:\", end=\"\\n>\\t\")\n",
    "    categories = get_categories(docs)\n",
    "    for category in categories:\n",
    "        print(\" {}\".format(category), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d83a9ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q3.1.1]\n",
      ">\tProviding list of categories in the dataset:\n",
      ">\t LOC MONEY PERCENT GPE CARDINAL WORK_OF_ART EVENT ORDINAL PERSON ORG TIME NORP QUANTITY PRODUCT LANGUAGE LAW DATE FAC\n"
     ]
    }
   ],
   "source": [
    "q311(docs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8972e7f9",
   "metadata": {},
   "source": [
    "#### Q 3.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adb3ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_spacy_ents(old_spacy_ner):\n",
    "    allowed = [\"LOC\", \"ORG\", \"O\"]\n",
    "    mapping_dict = {\n",
    "        \"GPE\": \"LOC\",\n",
    "        \"PERSON\": \"PER\",\n",
    "        \"EVENT\": \"MISC\",\n",
    "        \"NORP\": \"MISC\",\n",
    "    }\n",
    "    spacy_ner = list()\n",
    "    for sent in old_spacy_ner:\n",
    "        sent_temp = list()\n",
    "        for token in sent:\n",
    "            is_otag = \"-\" not in token[1]\n",
    "            ent_label = token[1].split(\"-\")[1] if not is_otag else token[1]\n",
    "            if ent_label not in allowed:\n",
    "                if ent_label in mapping_dict.keys():\n",
    "                    ent_label = mapping_dict[ent_label]\n",
    "                else:\n",
    "                    ent_label = \"O\"\n",
    "                    is_otag = True\n",
    "            if is_otag:\n",
    "                sent_temp.append((token[0], ent_label))\n",
    "            else:\n",
    "                sent_temp.append((token[0], f\"{token[1][:2]}{ent_label}\"))\n",
    "        spacy_ner.append(sent_temp)\n",
    "    return spacy_ner\n",
    "\n",
    "def q312(docs, corpus):\n",
    "    WORD, _, NE = range(3)\n",
    "    gt = list()\n",
    "    for s in corpus.iob_sents():\n",
    "        gt.append([(w[WORD], w[NE]) for w in s])\n",
    "    spacy_ner = list()\n",
    "    for doc in docs:\n",
    "        current_sent = list()\n",
    "        for token in doc:\n",
    "            ent_type = token.ent_iob_\n",
    "            if token.ent_type_ != '':\n",
    "                ent_type += f\"-{token.ent_type_}\"\n",
    "            current_sent.append((token.text, ent_type))\n",
    "        spacy_ner.append(current_sent)\n",
    "\n",
    "\n",
    "    print(\"[Q3.1.2]\\n>\\tProviding overall accuracy:\")\n",
    "    print(\"\\n>\\t Raw results\")\n",
    "    results = evaluate(gt, spacy_ner)\n",
    "    pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
    "    pd_tbl.round(decimals=3)\n",
    "    print(pd_tbl)\n",
    "\n",
    "    print(\"\\n>\\t mapping spacy entity labels to grount truth\")\n",
    "    results = evaluate(gt, map_spacy_ents(spacy_ner))\n",
    "    pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
    "    pd_tbl.round(decimals=3)\n",
    "    print(pd_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93fb40d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q3.1.2]\n",
      ">\tProviding overall accuracy:\n",
      "\n",
      ">\t Raw results\n",
      "                    p         r         f      s\n",
      "LOC          0.603352  0.020291  0.039262  10645\n",
      "MONEY        0.000000  0.000000  0.000000      0\n",
      "PERCENT      0.000000  0.000000  0.000000      0\n",
      "GPE          0.000000  0.000000  0.000000      0\n",
      "CARDINAL     0.000000  0.000000  0.000000      0\n",
      "WORK_OF_ART  0.000000  0.000000  0.000000      0\n",
      "EVENT        0.000000  0.000000  0.000000      0\n",
      "ORDINAL      0.000000  0.000000  0.000000      0\n",
      "PERSON       0.000000  0.000000  0.000000      0\n",
      "ORG          0.417543  0.263971  0.323454   9323\n",
      "MISC         1.000000  0.000000  0.000000   5062\n",
      "PER          1.000000  0.000000  0.000000  10059\n",
      "TIME         0.000000  0.000000  0.000000      0\n",
      "NORP         0.000000  0.000000  0.000000      0\n",
      "QUANTITY     0.000000  0.000000  0.000000      0\n",
      "PRODUCT      0.000000  0.000000  0.000000      0\n",
      "LANGUAGE     0.000000  0.000000  0.000000      0\n",
      "LAW          0.000000  0.000000  0.000000      0\n",
      "DATE         0.000000  0.000000  0.000000      0\n",
      "FAC          0.000000  0.000000  0.000000      0\n",
      "total        0.055107  0.076292  0.063992  35089\n",
      "\n",
      ">\t mapping spacy entity labels to grount truth\n",
      "              p         r         f      s\n",
      "PER    0.727109  0.600756  0.657921  10059\n",
      "MISC   0.832217  0.539905  0.654925   5062\n",
      "LOC    0.785684  0.701174  0.741028  10645\n",
      "ORG    0.417543  0.263971  0.323454   9323\n",
      "total  0.692912  0.532959  0.602500  35089\n"
     ]
    }
   ],
   "source": [
    "q312(docs_all, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f50038",
   "metadata": {},
   "source": [
    "#### Q 3.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "936259e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q313(docs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26b6c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "q313(docs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d669ee84",
   "metadata": {},
   "source": [
    "## Task 4: BONUS PART (extra mark for laude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e126cad",
   "metadata": {},
   "source": [
    "### Save old parser configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e81ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.transitionparser import Configuration, TransitionParser\n",
    "old_extract_features = Configuration.extract_features\n",
    "old_train = TransitionParser.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a5668a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package dependency_treebank to\n",
      "[nltk_data]     /home/pips/nltk_data...\n",
      "[nltk_data]   Package dependency_treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import types\n",
    "from nltk import download\n",
    "download('dependency_treebank')\n",
    "from nltk.corpus import dependency_treebank\n",
    "from nltk.parse import DependencyEvaluator\n",
    "\n",
    "# split the dataset into train and test\n",
    "# first 100 as train dataset and last 10 as test dataset\n",
    "train_dataset = dependency_treebank.parsed_sents()[:100]\n",
    "test_dataset =  dependency_treebank.parsed_sents()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e5177f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 100\n",
      " Number of valid (projective) examples : 100\n",
      "original labelled attachment score  0.7875\n",
      "original unlabelled attachment score 0.7875\n"
     ]
    }
   ],
   "source": [
    "Configuration.extract_features = old_extract_features\n",
    "tp = TransitionParser('arc-standard')\n",
    "tp.train(train_dataset, 'tp.model', verbose=False)\n",
    "# print(tp)\n",
    "\n",
    "# parsing takes a list of dependency graphs and a model as arguments\n",
    "parses = tp.parse(test_dataset, 'tp.model')\n",
    "# print(len(parses))\n",
    "# print(parses[0])\n",
    "\n",
    "# evaluating the parser\n",
    "de = DependencyEvaluator(parses, test_dataset)\n",
    "las, uas = de.eval()\n",
    "\n",
    "# no labels, thus identical\n",
    "print(\"original labelled attachment score \",las)\n",
    "print(\"original unlabelled attachment score\",uas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f56fc4f",
   "metadata": {},
   "source": [
    "### Q 4.1\n",
    "- Modify NLTK Transition parser's Configuration calss to use better features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b182ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STK_0_POS_TOP',\n",
       " 'STK_0_CTAG_TOP',\n",
       " 'BUF_0_FORM_Economic',\n",
       " 'BUF_0_LEMMA_Economic',\n",
       " 'BUF_0_POS_JJ',\n",
       " 'BUF_0_CTAG_JJ',\n",
       " 'BUF_0_HEAD_2',\n",
       " 'BUF_0_REL_ATT',\n",
       " 'BUF_1_LEMMA_news',\n",
       " 'BUF_1_POS_NN',\n",
       " 'BUF_2_POS_VBD',\n",
       " 'BUF_3_POS_JJ',\n",
       " 'BUF_4_POS_NN']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.parse import DependencyGraph\n",
    "def new_extract_features(self):\n",
    "    \"\"\"\n",
    "    Extract the set of features for the current configuration. Implement standard features as describe in\n",
    "    Table 3.2 (page 31) in Dependency Parsing book by Sandra Kubler, Ryan McDonal, Joakim Nivre.\n",
    "    Please note that these features are very basic.\n",
    "    :return: list(str)\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # print(\"n\", end=\" \")\n",
    "    if len(self.stack) > 0:\n",
    "        # Stack 0\n",
    "        stack_idx0 = self.stack[len(self.stack) - 1]\n",
    "        token = self._tokens[stack_idx0]\n",
    "        # print (token)\n",
    "        if self._check_informative(token[\"word\"], True):\n",
    "            result.append(\"STK_0_FORM_\" + token[\"word\"])\n",
    "        if \"lemma\" in token and self._check_informative(token[\"lemma\"]):\n",
    "            result.append(\"STK_0_LEMMA_\" + token[\"lemma\"])\n",
    "        if self._check_informative(token[\"tag\"]):\n",
    "            result.append(\"STK_0_POS_\" + token[\"tag\"])\n",
    "        if self._check_informative(token[\"ctag\"], True):\n",
    "            result.append(\"STK_0_CTAG_\" + token[\"ctag\"])\n",
    "        if self._check_informative(token[\"head\"], True):\n",
    "            result.append(\"STK_0_HEAD_\" + str(token[\"head\"]))\n",
    "        if self._check_informative(token[\"rel\"]):\n",
    "            result.append(\"BUF_0_REL_\" + token[\"rel\"])\n",
    "        if \"feats\" in token and self._check_informative(token[\"feats\"]):\n",
    "            feats = token[\"feats\"].split(\"|\")\n",
    "            for feat in feats:\n",
    "                result.append(\"STK_0_FEATS_\" + feat)\n",
    "        # Stack 1\n",
    "        if len(self.stack) > 1:\n",
    "            stack_idx1 = self.stack[len(self.stack) - 2]\n",
    "            token = self._tokens[stack_idx1]\n",
    "            if self._check_informative(token[\"tag\"]):\n",
    "                result.append(\"STK_1_POS_\" + token[\"tag\"])\n",
    "\n",
    "        # Left most, right most dependency of stack[0]\n",
    "        left_most = 1000000\n",
    "        right_most = -1\n",
    "        dep_left_most = \"\"\n",
    "        dep_right_most = \"\"\n",
    "        for (wi, r, wj) in self.arcs:\n",
    "            if wi == stack_idx0:\n",
    "                if (wj > wi) and (wj > right_most):\n",
    "                    right_most = wj\n",
    "                    dep_right_most = r\n",
    "                if (wj < wi) and (wj < left_most):\n",
    "                    left_most = wj\n",
    "                    dep_left_most = r\n",
    "        if self._check_informative(dep_left_most):\n",
    "            result.append(\"STK_0_LDEP_\" + dep_left_most)\n",
    "        if self._check_informative(dep_right_most):\n",
    "            result.append(\"STK_0_RDEP_\" + dep_right_most)\n",
    "\n",
    "    # Check Buffered 0\n",
    "    if len(self.buffer) > 0:\n",
    "        # Buffer 0\n",
    "        buffer_idx0 = self.buffer[0]\n",
    "        token = self._tokens[buffer_idx0]\n",
    "        if self._check_informative(token[\"word\"], True):\n",
    "            result.append(\"BUF_0_FORM_\" + token[\"word\"])\n",
    "        if \"lemma\" in token and self._check_informative(token[\"lemma\"]):\n",
    "            result.append(\"BUF_0_LEMMA_\" + token[\"lemma\"])\n",
    "        if self._check_informative(token[\"tag\"]):\n",
    "            result.append(\"BUF_0_POS_\" + token[\"tag\"])\n",
    "        if self._check_informative(token[\"ctag\"]):\n",
    "            result.append(\"BUF_0_CTAG_\" + token[\"ctag\"])\n",
    "        if self._check_informative(token[\"head\"]):\n",
    "            result.append(\"BUF_0_HEAD_\" + str(token[\"head\"]))\n",
    "        if self._check_informative(token[\"rel\"]):\n",
    "            result.append(\"BUF_0_REL_\" + token[\"rel\"])\n",
    "        if \"feats\" in token and self._check_informative(token[\"feats\"]):\n",
    "            feats = token[\"feats\"].split(\"|\")\n",
    "            for feat in feats:\n",
    "                result.append(\"BUF_0_FEATS_\" + feat)\n",
    "        # Buffer 1\n",
    "        if len(self.buffer) > 1:\n",
    "            buffer_idx1 = self.buffer[1]\n",
    "            token = self._tokens[buffer_idx1]\n",
    "            ### DISCARDED\n",
    "            # if self._check_informative(token[\"word\"], True):\n",
    "            #     result.append(\"BUF_1_FORM_\" + token[\"word\"])\n",
    "            # if self._check_informative(token[\"head\"]):\n",
    "            #     result.append(\"BUF_1_HEAD_\" + str(token[\"head\"]))\n",
    "            if self._check_informative(token[\"lemma\"], True):\n",
    "                result.append(\"BUF_1_LEMMA_\" + token[\"lemma\"])\n",
    "            if self._check_informative(token[\"tag\"]):\n",
    "                result.append(\"BUF_1_POS_\" + token[\"tag\"])\n",
    "        if len(self.buffer) > 2:\n",
    "            buffer_idx2 = self.buffer[2]\n",
    "            token = self._tokens[buffer_idx2]\n",
    "            if self._check_informative(token[\"tag\"]):\n",
    "                result.append(\"BUF_2_POS_\" + token[\"tag\"])\n",
    "        if len(self.buffer) > 3:\n",
    "            buffer_idx3 = self.buffer[3]\n",
    "            token = self._tokens[buffer_idx3]\n",
    "            if self._check_informative(token[\"tag\"]):\n",
    "                result.append(\"BUF_3_POS_\" + token[\"tag\"])\n",
    "        if len(self.buffer) > 4:\n",
    "            buffer_idx4 = self.buffer[4]\n",
    "            token = self._tokens[buffer_idx4]\n",
    "            if self._check_informative(token[\"tag\"]):\n",
    "                result.append(\"BUF_4_POS_\" + token[\"tag\"])\n",
    "                # Left most, right most dependency of stack[0]\n",
    "        left_most = 1000000\n",
    "        right_most = -1\n",
    "        dep_left_most = \"\"\n",
    "        dep_right_most = \"\"\n",
    "        for (wi, r, wj) in self.arcs:\n",
    "            if wi == buffer_idx0:\n",
    "                if (wj > wi) and (wj > right_most):\n",
    "                    right_most = wj\n",
    "                    dep_right_most = r\n",
    "                if (wj < wi) and (wj < left_most):\n",
    "                    left_most = wj\n",
    "                    dep_left_most = r\n",
    "        if self._check_informative(dep_left_most):\n",
    "            result.append(\"BUF_0_LDEP_\" + dep_left_most)\n",
    "        if self._check_informative(dep_right_most):\n",
    "            result.append(\"BUF_0_RDEP_\" + dep_right_most)\n",
    "\n",
    "    return result\n",
    "\n",
    "Configuration.extract_features = new_extract_features\n",
    "\n",
    "\n",
    "gold_sent = DependencyGraph(\"\"\"\n",
    "Economic  JJ     2      ATT\n",
    "news  NN     3       SBJ\n",
    "has       VBD       0       ROOT\n",
    "little      JJ      5       ATT\n",
    "effect   NN     3       OBJ\n",
    "on     IN      5       ATT\n",
    "financial       JJ       8       ATT\n",
    "markets    NNS      6       PC\n",
    ".    .      3       PU\n",
    "\"\"\")\n",
    "\n",
    "# for s in gold_sent.triples():\n",
    "#     print(s)\n",
    "\n",
    "conf = Configuration(gold_sent)\n",
    "# print(conf)\n",
    "conf.extract_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ebf011",
   "metadata": {},
   "source": [
    "### Q 4.2\n",
    "- Evaluate the features comparing performance to the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e5177f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of training examples : 100\n",
      " Number of valid (projective) examples : 100\n",
      "modified labelled attachment score 0.8\n",
      "modified unlabelled attachment score 0.8\n"
     ]
    }
   ],
   "source": [
    "Configuration.extract_features = new_extract_features\n",
    "# using the TransitionParser \n",
    "tp_new_fe = TransitionParser('arc-standard')\n",
    "# replacing the train function with the modified one\n",
    "# tp_new_fe = types.MethodType(train,tp_new_fe)\n",
    "tp_new_fe.train(train_dataset, 'tp_new_fe.model', verbose=False)\n",
    "# print(tp)\n",
    "\n",
    "# parsing takes a list of dependency graphs and a model as arguments\n",
    "parses_new_fe = tp_new_fe.parse(test_dataset, 'tp_new_fe.model')\n",
    "# print(len(parses_new_fe))\n",
    "# print(parses_new_fe[0])\n",
    "\n",
    "de_new_fe = DependencyEvaluator(parses_new_fe, test_dataset)\n",
    "las_new_fe, uas_new_fe = de_new_fe.eval()\n",
    "\n",
    "# no labels, thus identical\n",
    "print('modified labelled attachment score',las_new_fe)\n",
    "print('modified unlabelled attachment score',uas_new_fe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa4657c",
   "metadata": {},
   "source": [
    "### Q 4.3\n",
    "- Replace SVM classifier with an alternative of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "93b94966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR CLASSIFIER\n",
      "\n",
      " Number of training examples : 100\n",
      " Number of valid (projective) examples : 100\n",
      "modified classifier labelled attachment score 0.6833333333333333\n",
      "modified classifier unlabelled attachment score 0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tempfile\n",
    "try:\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.datasets import load_svmlight_file\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "def sgd_train(self, depgraphs, modelfile, verbose=True):\n",
    "    \"\"\"\n",
    "    :param depgraphs : list of DependencyGraph as the training data\n",
    "    :type depgraphs : DependencyGraph\n",
    "    :param modelfile : file name to save the trained model\n",
    "    :type modelfile : str\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        input_file = tempfile.NamedTemporaryFile(\n",
    "            prefix=\"transition_parse.train\", dir=tempfile.gettempdir(), delete=False\n",
    "        )\n",
    "\n",
    "        if self._algorithm == self.ARC_STANDARD:\n",
    "            self._create_training_examples_arc_std(depgraphs, input_file)\n",
    "        else:\n",
    "            self._create_training_examples_arc_eager(depgraphs, input_file)\n",
    "\n",
    "        input_file.close()\n",
    "        # Using the temporary file to train the libsvm classifier\n",
    "        x_train, y_train = load_svmlight_file(input_file.name)\n",
    "\n",
    "        model = SGDClassifier(\n",
    "            loss=\"log\",\n",
    "            penalty=\"l2\",\n",
    "            shuffle=True,\n",
    "            verbose=0,\n",
    "            learning_rate=\"optimal\"\n",
    "        )\n",
    "        model.fit(x_train, y_train)\n",
    "        # Save the model to file name (as pickle)\n",
    "        pickle.dump(model, open(modelfile, \"wb\"))\n",
    "    finally:\n",
    "        os.remove(input_file.name)\n",
    "\n",
    "print(\"LINEAR CLASSIFIER\\n\")\n",
    "tp_sgd_clf = TransitionParser('arc-standard')\n",
    "tp_sgd_clf.train = types.MethodType(sgd_train,tp_sgd_clf)\n",
    "tp_sgd_clf.train(train_dataset, 'tp_sgd_clf.model', verbose=False)\n",
    "parses_sgd_clf = tp_sgd_clf.parse(test_dataset, 'tp_sgd_clf.model')\n",
    "de_sgd_clf = DependencyEvaluator(parses_sgd_clf, test_dataset)\n",
    "las_sgd_clf, uas_sgd_clf = de_sgd_clf.eval()\n",
    "print('modified classifier labelled attachment score',las_sgd_clf)\n",
    "print('modified classifier unlabelled attachment score',uas_sgd_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93b94966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST CLASSIFIER\n",
      "\n",
      " Number of training examples : 100\n",
      " Number of valid (projective) examples : 100\n",
      "modified classifier labelled attachment score 0.7583333333333333\n",
      "modified classifier unlabelled attachment score 0.7583333333333333\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tempfile\n",
    "try:\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.datasets import load_svmlight_file\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "def rf_train(self, depgraphs, modelfile, verbose=True):\n",
    "    \"\"\"\n",
    "    :param depgraphs : list of DependencyGraph as the training data\n",
    "    :type depgraphs : DependencyGraph\n",
    "    :param modelfile : file name to save the trained model\n",
    "    :type modelfile : str\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        input_file = tempfile.NamedTemporaryFile(\n",
    "            prefix=\"transition_parse.train\", dir=tempfile.gettempdir(), delete=False\n",
    "        )\n",
    "\n",
    "        if self._algorithm == self.ARC_STANDARD:\n",
    "            self._create_training_examples_arc_std(depgraphs, input_file)\n",
    "        else:\n",
    "            self._create_training_examples_arc_eager(depgraphs, input_file)\n",
    "\n",
    "        input_file.close()\n",
    "        # Using the temporary file to train the libsvm classifier\n",
    "        x_train, y_train = load_svmlight_file(input_file.name)\n",
    "\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            criterion=\"entropy\",\n",
    "            max_features=\"log2\"\n",
    "        )\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        # Save the model to file name (as pickle)\n",
    "        pickle.dump(model, open(modelfile, \"wb\"))\n",
    "    finally:\n",
    "        os.remove(input_file.name)\n",
    "\n",
    "print(\"RANDOM FOREST CLASSIFIER\\n\")\n",
    "tp_rf_clf = TransitionParser('arc-standard')\n",
    "tp_rf_clf.train = types.MethodType(rf_train,tp_rf_clf)\n",
    "tp_rf_clf.train(train_dataset, 'tp_rf_clf.model', verbose=False)\n",
    "parses_rf_clf = tp_rf_clf.parse(test_dataset, 'tp_rf_clf.model')\n",
    "de_rf_clf = DependencyEvaluator(parses_rf_clf, test_dataset)\n",
    "las_rf_clf, uas_rf_clf = de_rf_clf.eval()\n",
    "print('modified classifier labelled attachment score',las_rf_clf)\n",
    "print('modified classifier unlabelled attachment score',uas_rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "93b94966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP CLASSIFIER\n",
      "\n",
      " Number of training examples : 100\n",
      " Number of valid (projective) examples : 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pips/Projects/NLU-UniTN-2022/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified classifier labelled attachment score 0.7708333333333334\n",
      "modified classifier unlabelled attachment score 0.7708333333333334\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tempfile\n",
    "try:\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.datasets import load_svmlight_file\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "def mlp_train(self, depgraphs, modelfile, verbose=True):\n",
    "    \"\"\"\n",
    "    :param depgraphs : list of DependencyGraph as the training data\n",
    "    :type depgraphs : DependencyGraph\n",
    "    :param modelfile : file name to save the trained model\n",
    "    :type modelfile : str\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        input_file = tempfile.NamedTemporaryFile(\n",
    "            prefix=\"transition_parse.train\", dir=tempfile.gettempdir(), delete=False\n",
    "        )\n",
    "\n",
    "        if self._algorithm == self.ARC_STANDARD:\n",
    "            self._create_training_examples_arc_std(depgraphs, input_file)\n",
    "        else:\n",
    "            self._create_training_examples_arc_eager(depgraphs, input_file)\n",
    "\n",
    "        input_file.close()\n",
    "        # Using the temporary file to train the libsvm classifier\n",
    "        x_train, y_train = load_svmlight_file(input_file.name)\n",
    "        \n",
    "        model = MLPClassifier(\n",
    "            activation=\"relu\", \n",
    "            learning_rate=\"adaptive\",\n",
    "            solver='sgd', \n",
    "            nesterovs_momentum=True,\n",
    "            alpha=1e-5,\n",
    "            hidden_layer_sizes=(20,50,20), \n",
    "            random_state=1\n",
    "            )\n",
    "\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        # Save the model to file name (as pickle)\n",
    "        pickle.dump(model, open(modelfile, \"wb\"))\n",
    "    finally:\n",
    "        os.remove(input_file.name)\n",
    "\n",
    "print(\"MLP CLASSIFIER\\n\")\n",
    "tp_mlp_clf = TransitionParser('arc-standard')\n",
    "tp_mlp_clf.train = types.MethodType(mlp_train,tp_mlp_clf)\n",
    "tp_mlp_clf.train(train_dataset, 'tp_mlp_clf.model', verbose=False)\n",
    "parses_mlp_clf = tp_mlp_clf.parse(test_dataset, 'tp_mlp_clf.model')\n",
    "de_mlp_clf = DependencyEvaluator(parses_mlp_clf, test_dataset)\n",
    "las_mlp_clf, uas_mlp_clf = de_mlp_clf.eval()\n",
    "print('modified classifier labelled attachment score',las_mlp_clf)\n",
    "print('modified classifier unlabelled attachment score',uas_mlp_clf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8ea92f07f1cce96500be7f9231af4df2b17add51555df0958a949f03550b4d9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
